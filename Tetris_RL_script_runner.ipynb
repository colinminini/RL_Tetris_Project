{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tetris RL script runner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4563c7",
   "metadata": {},
   "source": [
    "## Baseline policies (render)\n",
    "\n",
    "These open a window to visualize the episode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3299b64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Over!\n",
      "Final Score: 12\n"
     ]
    }
   ],
   "source": [
    "!python3 tetris_code/view_episode_policy_random.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6ec8e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Over!\n",
      "Final Score: 212\n"
     ]
    }
   ],
   "source": [
    "!python3 tetris_code/view_episode_policy_greedy.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97c2862b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Over!\n",
      "Final Score: 11\n"
     ]
    }
   ],
   "source": [
    "!python3 tetris_code/view_episode_policy_down.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5bfb0454784b7ea7b97995b79d484d",
   "metadata": {},
   "source": [
    "## Baseline policy evaluation (greedy)\n",
    "\n",
    "Compute average env return for the greedy policy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2011c5b47de44b0b30f158a526fa944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward of episodes [  92.  286.   68.   57.  792.  273.   85.   51. 1692.  918.]\n",
      "Average reward 431.4  +/-  212.49329401183465\n"
     ]
    }
   ],
   "source": [
    "!python3 tetris_code/evaluate_policy_greedy.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd7e68f",
   "metadata": {},
   "source": [
    "## Train DQN with after-states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0be9797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10/200 avg_return=-138.29 epsilon=0.993\n",
      "Episode 20/200 avg_return=-123.23 epsilon=0.987\n",
      "Episode 30/200 avg_return=-139.55 epsilon=0.979\n",
      "Episode 40/200 avg_return=-133.19 epsilon=0.973\n",
      "Episode 50/200 avg_return=-133.87 epsilon=0.967\n",
      "Episode 60/200 avg_return=-131.29 epsilon=0.961\n",
      "Episode 70/200 avg_return=-132.90 epsilon=0.955\n",
      "Episode 80/200 avg_return=-140.77 epsilon=0.949\n",
      "Episode 90/200 avg_return=-125.58 epsilon=0.942\n",
      "Episode 100/200 avg_return=-136.02 epsilon=0.935\n",
      "Episode 110/200 avg_return=-126.92 epsilon=0.928\n",
      "Episode 120/200 avg_return=-116.13 epsilon=0.921\n",
      "Episode 130/200 avg_return=-131.61 epsilon=0.915\n",
      "Episode 140/200 avg_return=-146.44 epsilon=0.908\n",
      "Episode 150/200 avg_return=-126.37 epsilon=0.902\n",
      "Episode 160/200 avg_return=-142.43 epsilon=0.897\n",
      "Episode 170/200 avg_return=-130.71 epsilon=0.890\n",
      "Episode 180/200 avg_return=-127.28 epsilon=0.883\n",
      "Episode 190/200 avg_return=-138.52 epsilon=0.877\n",
      "Episode 200/200 avg_return=-125.85 epsilon=0.870\n",
      "Saved checkpoint to DQN_scripts/checkpoints/dqn_afterstate.pt\n"
     ]
    }
   ],
   "source": [
    "!python3 -m DQN_scripts.train_dqn_afterstate --episodes 200 --save-path DQN_scripts/checkpoints/dqn_afterstate.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebef601",
   "metadata": {},
   "source": [
    "## Evaluate the DQN after-state agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c797eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env return of episodes [27927.  9881. 37193. 12814.  7300.  1013. 15675. 24387. 18292. 50610.]\n",
      "Average env return 20509.2  +/-  7884.025773676796\n"
     ]
    }
   ],
   "source": [
    "!python3 -m DQN_scripts.evaluate_dqn_afterstate --episodes 10 --model-path DQN_scripts/checkpoints/dqn_afterstate.pt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a70ba03",
   "metadata": {},
   "source": [
    "## Render a DQN episode\n",
    "\n",
    "This will open a window to visualize the trained agent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cb2168",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m DQN_scripts.evaluate_dqn_afterstate --episodes 1 --model-path DQN_scripts/checkpoints/dqn_afterstate.pt --render\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
